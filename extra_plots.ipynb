{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from SCM import ScalarLinearDecisionModel, NewScalarLinearDecisionModel, SelectionBiasDecisionModel\n",
    "import graph_helper as graph#line_plots, importance_heatmap, diff_importance_heatmap, categorical_heatmap\n",
    "import optimization_helper as opt #find_pred_improve_lin_cost, find_real_improve_lin_cost\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358dd6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(X, Y):\n",
    "    cm = confusion_matrix(X, Y)\n",
    "    TN = cm[0][0]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "    TP = cm[1][1]\n",
    "\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (TN + FP)\n",
    "    FNR = FN / (TP + FN)\n",
    "    TPR = TP / (TP + FN)\n",
    "    \n",
    "    # Print the rates\n",
    "    print(\"True Negative Rate (TNR):\", TNR)\n",
    "    print(\"False Positive Rate (FPR):\", FPR)\n",
    "    print(\"False Negative Rate (FNR):\", FNR)\n",
    "    print(\"True Positive Rate (TPR):\", TPR)\n",
    "\n",
    "def fair_model_comp(params, delta = 0.5):\n",
    "    data_train = NewScalarLinearDecisionModel(params)\n",
    "    data_train.generate_basic_data()\n",
    "    data_train_pd = data_train.get_data_df()\n",
    "    print(\"Using both features A and C\")\n",
    "    X_AC = np.column_stack((data_train_pd[\"A\"], data_train_pd[\"C\"]))\n",
    "    model_AC = LogisticRegression()\n",
    "    model_AC.fit(X_AC, data_train_pd[\"Y\"])\n",
    "    line_AC = {'w': model_AC.coef_.flatten(), 'b': model_AC.intercept_[0]} \n",
    "    print(\"Training on A and C:\")\n",
    "    print(\"score: \", model_AC.score(X_AC, data_train_pd[\"Y\"]))\n",
    "    print(\"gaming\")\n",
    "    g_data_AC = gaming_metric(params, data_train, line_AC, delta = delta)\n",
    "    print(\"minority: \", g_data_AC[0], \", majority: \",  g_data_AC[1])\n",
    "    print(\"improvement\")\n",
    "    i_data_AC = improvement_metric(params, data_train, line_AC, delta = delta)\n",
    "    print(\"minority: \", i_data_AC[0], \", majority: \",  i_data_AC[1])\n",
    "    '''print(\"Minority:\")\n",
    "    print(confusion(data_train_pd[\"Y\"][data_train_pd[\"S\"] == 0], model_AC.predict(X_AC[data_train_pd[\"S\"] == 0])))\n",
    "    print(\"Majority:\")\n",
    "    print(confusion(data_train_pd[\"Y\"][data_train_pd[\"S\"] == 1], model_AC.predict(X_AC[data_train_pd[\"S\"] == 1])))\n",
    "    '''\n",
    "    print(\"Using only feature C\")\n",
    "    X_C = np.array([data_train_pd[\"C\"]]).T\n",
    "    model_C = LogisticRegression()\n",
    "    model_C.fit(X_C, data_train_pd[\"Y\"])\n",
    "    c_boundary = data_train.get_real_boundary(s=1, u=0) #s doesn't matter\n",
    "    line_C = {'w': np.array([0, c_boundary]), 'b': 0} \n",
    "    print(c_boundary)\n",
    "    #line_C = {'w': np.array([0, model_AC.coef_.flatten()[1]]), 'b': model_C.intercept_[0] + model_AC.coef_.flatten()[0]} \n",
    "    print(\"Training just on C:\")\n",
    "    print(\"score: \", model_C.score(X_C, data_train_pd[\"Y\"]))\n",
    "    print(\"improvement\")\n",
    "    i_data_C = improvement_metric(params, data_train, line_C, delta = delta)\n",
    "    print(\"minority: \", i_data_C[0], \", majority: \",  i_data_C[1])\n",
    "    print(\"gaming\")\n",
    "    g_data_C = gaming_metric(params, data_train, line_C, delta = delta)\n",
    "    print(\"minority: \", g_data_C[0], \", majority: \",  g_data_C[1])\n",
    "    \n",
    "    '''print(\"Minority:\")\n",
    "    print(confusion(data_train_pd[\"Y\"][data_train_pd[\"S\"] == 0], model_C.predict(X_C[data_train_pd[\"S\"] == 0])))\n",
    "    print(\"Majority:\")\n",
    "    print(confusion(data_train_pd[\"Y\"][data_train_pd[\"S\"] == 1], model_C.predict(X_C[data_train_pd[\"S\"] == 1])))\n",
    "    #Errors\n",
    "    print(\"Minority Error:\")\n",
    "    print(np.mean(np.abs(model_C.predict(X_C[data_train_pd[\"S\"] == 0]) - model_AC.predict(X_AC[data_train_pd[\"S\"] == 0]))))\n",
    "    print(\"Majority Error:\")\n",
    "    print(np.mean(np.abs(model_C.predict(X_C[data_train_pd[\"S\"] == 1]) - model_AC.predict(X_AC[data_train_pd[\"S\"] == 1]))))\n",
    "    #print(\"[[true negative, false positive],\")\n",
    "    #print(\"[false negative, true positive]]\")'''\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
